{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "28d91565",
            "metadata": {},
            "source": [
                "# Data Analysis 2 – Login Feature Clustering\n",
                "\n",
                "This notebook loads the transaction and behaviour datasets, extracts the specified login‑related features, computes descriptive statistics, builds a clustering model (KMeans with PCA), and visualises the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "9e8f35ac",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.cluster import KMeans\n",
                "\n",
                "%matplotlib inline\n",
                "sns.set_style('whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (14, 8)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd032b3f",
            "metadata": {},
            "outputs": [
                {
                    "ename": "FileNotFoundError",
                    "evalue": "Unable to read ../docs/транзакции в Мобильном интернет Банкинге.csv",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m                 \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnable to read \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m tx = \u001b[43mload_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTX_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m beh = load_csv(BEH_PATH)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Normalise column names (remove surrounding whitespace)\u001b[39;00m\n",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mload_csv\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     15\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m     16\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnable to read \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
                        "\u001b[31mFileNotFoundError\u001b[39m: Unable to read ../docs/транзакции в Мобильном интернет Банкинге.csv"
                    ]
                }
            ],
            "source": [
                "# Paths (adjust if needed)\n",
                "TX_PATH = '../docs/транзакции в Мобильном интернет Банкинге.csv'\n",
                "BEH_PATH = '../docs/поведенческие паттерны клиентов.csv'\n",
                "\n",
                "def load_csv(path):\n",
                "    # CSV files have the real header on the second line (row index 1)\n",
                "    # We skip the first row and use the second as column names\n",
                "    for enc in ('cp1251', 'utf-8', 'latin1'):\n",
                "        for sep in (';', '\\t', ','):\n",
                "            try:\n",
                "                df = pd.read_csv(path, encoding=enc, sep=sep, engine='python', header=1)\n",
                "                if df.shape[1] > 1:\n",
                "                    return df\n",
                "            except Exception:\n",
                "                pass\n",
                "    raise FileNotFoundError(f'Unable to read {path}')\n",
                "\n",
                "tx = load_csv(TX_PATH)\n",
                "beh = load_csv(BEH_PATH)\n",
                "\n",
                "# Normalise column names (remove surrounding whitespace)\n",
                "tx.columns = [str(c).strip() for c in tx.columns]\n",
                "beh.columns = [str(c).strip() for c in beh.columns]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "d706ce74",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Identify customer id column (cst_dim_id is the canonical name)\n",
                "def find_id(cols):\n",
                "    candidates = ['cst_dim_id', 'cust', 'client', 'customer', 'id']\n",
                "    for cand in candidates:\n",
                "        for c in cols:\n",
                "            if cand.lower() in str(c).lower():\n",
                "                return c\n",
                "    return cols[0]\n",
                "\n",
                "cust_tx = find_id(tx.columns)\n",
                "cust_beh = find_id(beh.columns)\n",
                "tx['cust_id'] = tx[cust_tx].astype(str).str.strip()\n",
                "beh['cust_id'] = beh[cust_beh].astype(str).str.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e93b60cf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Detected target column: None\n",
                        "Warning: target column not found – all rows set to 0\n"
                    ]
                },
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "# Find target label – column name must be exactly 'target' (or one of the common aliases)\n",
                "def find_target(cols):\n",
                "    for cand in ['target', 'is_fraud', 'fraud', 'label']:\n",
                "        for c in cols:\n",
                "            if cand.lower() in str(c).lower():\n",
                "                return c\n",
                "    # fallback: assume a column literally called 'target' exists\n",
                "    if 'target' in cols:\n",
                "        return 'target'\n",
                "    return None\n",
                "\n",
                "target_col = find_target(beh.columns)\n",
                "print(f\"Detected target column: {target_col}\")\n",
                "\n",
                "if target_col:\n",
                "    # The column should already contain 0/1 values; coerce to int just in case\n",
                "    beh['target'] = beh[target_col].astype(int)\n",
                "else:\n",
                "    beh['target'] = 0\n",
                "    print('Warning: target column not found – all rows set to 0')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "42620076",
            "metadata": {},
            "outputs": [],
            "source": [
                "# List of login‑related features required by the user\n",
                "login_features = [\n",
                "    'logins_last_7_days', 'logins_last_30_days',\n",
                "    'login_frequency_7d', 'login_frequency_30d',\n",
                "    'freq_change_7d_vs_mean', 'logins_7d_over_30d_ratio',\n",
                "    'avg_login_interval_30d', 'std_login_interval_30d', 'var_login_interval_30d', 'ewm_login_interval_7d',\n",
                "    'burstiness_login_interval', 'fano_factor_login_interval', 'zscore_avg_login_interval_7d'\n",
                "]\n",
                "\n",
                "# Keep only columns that actually exist (case‑insensitive match)\n",
                "present_features = []\n",
                "for f in login_features:\n",
                "    matches = [cc for c in tx.columns if f.lower() == str(c).lower()]\n",
                "    if matches:\n",
                "        present_features.append(matches[0])\n",
                "\n",
                "print('Features found:', present_features)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "24b0b753",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Subset and coerce to numeric\n",
                "tx_sub = tx[['cust_id'] + present_features].copy()\n",
                "for col in present_features:\n",
                "    tx_sub[col] = pd.to_numeric(tx_sub[col].astype(str).str.replace(',', '.'), errors='cocoerce')\n",
                "\n",
                "# Merge with behaviour (target)\n",
                "merged = tx_sub.merge(beh[['cust_id', 'target']], on='cust_id', how='left')\n",
                "merged['target'] = merged['target'].fillna(0).astype(int)\n",
                "\n",
                "print('Merged shape:', merged.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1a37a789",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Descriptive statistics per class\n",
                "stats = merged.groupby('target')[present_features].describe().transpose()\n",
                "display(stats)\n",
                "\n",
                "# Simple summary table (mean per class)\n",
                "summary = merged.groupby('target')[present_features].mean().T\n",
                "summary.columns = ['Fraud', 'Non‑Fraud']\n",
                "display(summary)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb3e0e4c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Clustering pipeline\n",
                "X = merged[present_features].values\n",
                "imp = SimpleImputer(strategy='median')\n",
                "X_imp = imp.fit_transform(X)\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X_imp)\n",
                "\n",
                "# PCA for 2‑D visualisation\n",
                "pca = PCA(n_components=2, random_state=42)\n",
                "X_pca = pca.fit_transform(X_scaled)\n",
                "merged['pca1'] = X_pca[:, 0]\n",
                "merged['pca2'] = X_pca[:, 1]\n",
                "\n",
                "# KMeans (k=4)\n",
                "k = 4\n",
                "kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
                "merged['cluster'] = kmeans.fit_predict(X_scaled)\n",
                "\n",
                "print('Clustering completed. Cluster counts:')\n",
                "print(merged['cluster'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9b2da749",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualise PCA coloured by fraud label\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=merged, x='pca1', y='pca2', hue='target', palette=['#2ecc71', '#e74cc3cc'], alpha=0.7)\n",
                "plt.title('PCA of Login Features – Fraud vs Non‑Fraud')\n",
                "plt.legend(title='User Type', labels=['Non‑Fraud', 'Fraud'])\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a5dc79e5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualise PCA coloured by cluster\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=merged, x='pca1', y='pca2', hue='cluster', palette='tab10', alpha=0.7)\n",
                "plt.title('PCA of Login Features – KMeans Clusters')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f93c40e2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Mean feature values per cluster (bar chart)\n",
                "cluster_means = merged.groupby('cluster')[present_features].mean()\n",
                "cluster_means.T.plot(kind='bar', figsize=(12, 6))\n",
                "plt.title('Mean Login Features per Cluster')\n",
                "plt.ylabel('Mean value')\n",
                "plt.legend(title='Cluster')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8513fc0e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Correlation heatmap of the login features\n",
                "corr = merged[present_features].corr()\n",
                "plt.figure(figsize=(10, 8))\n",
                "sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
                "plt.title('Feature Correlation Heatmap')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "35a92748",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save artefacts\n",
                "merged.to_csv('login_features_merged.csv', index=False)\n",
                "cluster_summary = merged.groupby('cluster')[present_features].mean()\n",
                "cluster_summary.to_csv('cluster_summary_k4.csv')\n",
                "print('Files saved: login_features_merged.csv, cluster_summary_k4.csv')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}

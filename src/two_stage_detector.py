"""
Two-Stage Fraud Detection Pipeline
===================================

Stage 1: Scorecard (Rule-based fast filter)
Stage 2: ML Model (Deep analysis for suspicious cases)

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
    Transaction ‚Üí Scorecard ‚Üí Low risk? ‚Üí APPROVE
                           ‚Üí High risk? ‚Üí ML Model ‚Üí FRAUD/NOT_FRAUD
"""

import pandas as pd
import numpy as np
from typing import Dict, Tuple
import pickle
from catboost import CatBoostClassifier
import config


class ScorecardFilter:
    """Stage 1: Fast rule-based filter using scorecard logic."""
    
    def __init__(self, threshold_low: int = 2, threshold_high: int = 5):
        """
        Args:
            threshold_low: –°–∫–æ—Ä <= —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è ‚Üí AUTO APPROVE
            threshold_high: –°–∫–æ—Ä >= —ç—Ç–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è ‚Üí SEND TO ML MODEL
        """
        self.threshold_low = threshold_low
        self.threshold_high = threshold_high
        
    def calculate_scorecard(self, df: pd.DataFrame) -> pd.DataFrame:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ scorecard –±–∞–ª–ª–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.
        
        –ü—Ä–∞–≤–∏–ª–∞ (–∏–∑ —Ç–≤–æ–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞):
        - rare_os_flag = 1            ‚Üí +2 –±–∞–ª–ª–∞
        - rare_device_flag = 1        ‚Üí +2 –±–∞–ª–ª–∞
        - suspicious_device_combo = 1 ‚Üí +2 –±–∞–ª–ª–∞
        - high_device_volatility = 1  ‚Üí +1 –±–∞–ª–ª
        - high_login_volatility = 1   ‚Üí +1 –±–∞–ª–ª
        """
        df = df.copy()
        
        # 1. Rare OS (< 1% —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)
        if 'last_os_ver' in df.columns:
            os_counts = df['last_os_ver'].value_counts(normalize=True)
            df['rare_os_flag'] = df['last_os_ver'].map(
                lambda x: 1 if os_counts.get(x, 0) < 0.01 else 0
            )
        else:
            df['rare_os_flag'] = 0
        
        # 2. Rare Device (< 1% —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π)
        if 'last_phone_model' in df.columns:
            device_counts = df['last_phone_model'].value_counts(normalize=True)
            df['rare_device_flag'] = df['last_phone_model'].map(
                lambda x: 1 if device_counts.get(x, 0) < 0.01 else 0
            )
        else:
            df['rare_device_flag'] = 0
        
        # 3. High Device Volatility (—á–∞—Å—Ç–∞—è —Å–º–µ–Ω–∞ device/OS)
        volatility_features = ['os_count_30d', 'device_count_30d']
        if all(f in df.columns for f in volatility_features):
            volatility_threshold = df[volatility_features].mean(axis=1).quantile(0.75)
            df['high_device_volatility'] = (
                df[volatility_features].mean(axis=1) > volatility_threshold
            ).astype(int)
        else:
            df['high_device_volatility'] = 0
        
        # 4. Suspicious Device Combo
        df['suspicious_device_combo'] = df['rare_device_flag'] * df['high_device_volatility']
        
        # 5. High Login Volatility
        if 'login_volatility_factor' in df.columns:
            login_vol_threshold = df['login_volatility_factor'].quantile(0.80)
            df['high_login_volatility'] = (
                df['login_volatility_factor'] > login_vol_threshold
            ).astype(int)
        else:
            df['high_login_volatility'] = 0
        
        # 6. TOTAL SCORECARD SCORE
        df['scorecard_total'] = (
            df['rare_os_flag'] * 2 +
            df['rare_device_flag'] * 2 +
            df['suspicious_device_combo'] * 2 +
            df['high_device_volatility'] * 1 +
            df['high_login_volatility'] * 1
        )
        
        return df
    
    def filter_transactions(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
        """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –Ω–∞ 3 –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
        
        Returns:
            (auto_approve, needs_ml_check, scorecard_results)
        """
        df_scored = self.calculate_scorecard(df)
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è
        auto_approve = df_scored[df_scored['scorecard_total'] <= self.threshold_low].copy()
        needs_ml_check = df_scored[df_scored['scorecard_total'] > self.threshold_low].copy()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = {
            'total': len(df_scored),
            'auto_approve': len(auto_approve),
            'needs_ml_check': len(needs_ml_check),
            'approve_rate': len(auto_approve) / len(df_scored) * 100,
            'ml_check_rate': len(needs_ml_check) / len(df_scored) * 100
        }
        
        print(f"\nüìä SCORECARD FILTER RESULTS:")
        print(f"   Total transactions: {stats['total']}")
        print(f"   ‚úÖ Auto-approved: {stats['auto_approve']} ({stats['approve_rate']:.1f}%)")
        print(f"   üîç Needs ML check: {stats['needs_ml_check']} ({stats['ml_check_rate']:.1f}%)")
        
        return auto_approve, needs_ml_check, df_scored


class MLModelDetector:
    """Stage 2: Deep ML-based fraud detection for suspicious cases."""
    
    def __init__(self, model_path: str = 'models/catboost_fraud_model.cbm',
                 feature_names_path: str = 'models/feature_names.pkl'):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π CatBoost –º–æ–¥–µ–ª–∏."""
        self.model = CatBoostClassifier()
        self.model.load_model(model_path)
        
        with open(feature_names_path, 'rb') as f:
            self.feature_names = pickle.load(f)
        
        print(f"‚úÖ ML Model loaded: {model_path}")
        print(f"   Features: {len(self.feature_names)}")
    
    def predict(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ñ—Ä–æ–¥–∞ –¥–ª—è –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π.
        
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: fraud_probability, fraud_prediction, risk_level
        """
        df = df.copy()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –≤—Å–µ—Ö –Ω—É–∂–Ω—ã—Ö —Ñ–∏—á–µ–π
        missing_features = set(self.feature_names) - set(df.columns)
        if missing_features:
            print(f"‚ö†Ô∏è Warning: Missing features: {missing_features}")
            for feat in missing_features:
                df[feat] = 0
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        X = df[self.feature_names]
        df['fraud_probability'] = self.model.predict_proba(X)[:, 1]
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Ä–æ–≥–∏ –∏–∑ config
        df['fraud_prediction'] = (df['fraud_probability'] > 0.5).astype(int)
        
        # Risk levels
        df['risk_level'] = pd.cut(
            df['fraud_probability'],
            bins=[0, config.THRESHOLDS['low'], config.THRESHOLDS['medium'], 
                  config.THRESHOLDS['high'], 1.0],
            labels=['LOW', 'MEDIUM', 'HIGH', 'CRITICAL']
        )
        
        return df


class TwoStageDetector:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–≤—É—Ö—ç—Ç–∞–ø–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –¥–µ—Ç–µ–∫—Ü–∏–∏."""
    
    def __init__(self, scorecard_threshold_low: int = 2,
                 model_path: str = 'models/catboost_fraud_model.cbm'):
        """
        Args:
            scorecard_threshold_low: –°–∫–æ—Ä <= —ç—Ç–æ–≥–æ ‚Üí –∞–≤—Ç–æ-–æ–¥–æ–±—Ä–µ–Ω–∏–µ
            model_path: –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π ML –º–æ–¥–µ–ª–∏
        """
        self.scorecard = ScorecardFilter(threshold_low=scorecard_threshold_low)
        self.ml_model = MLModelDetector(model_path=model_path)
        
    def detect_fraud(self, df: pd.DataFrame) -> pd.DataFrame:
        """–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω –¥–µ—Ç–µ–∫—Ü–∏–∏ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞.
        
        Returns:
            DataFrame —Å–æ –≤—Å–µ–º–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–º —Ä–µ—à–µ–Ω–∏–µ–º
        """
        print("\n" + "="*60)
        print("üöÄ TWO-STAGE FRAUD DETECTION PIPELINE")
        print("="*60)
        
        # STAGE 1: Scorecard —Ñ–∏–ª—å—Ç—Ä
        print("\nüìã STAGE 1: Scorecard Filter...")
        auto_approve, needs_ml, df_scored = self.scorecard.filter_transactions(df)
        
        # –î–ª—è –∞–≤—Ç–æ-–æ–¥–æ–±—Ä–µ–Ω–Ω—ã—Ö: fraud_probability = 0
        auto_approve['fraud_probability'] = 0.0
        auto_approve['fraud_prediction'] = 0
        auto_approve['risk_level'] = 'LOW'
        auto_approve['detection_stage'] = 'scorecard'
        
        if len(needs_ml) == 0:
            print("\n‚úÖ All transactions auto-approved by scorecard!")
            return auto_approve
        
        # STAGE 2: ML Model –¥–ª—è –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö
        print(f"\nü§ñ STAGE 2: ML Model Analysis ({len(needs_ml)} transactions)...")
        needs_ml_analyzed = self.ml_model.predict(needs_ml)
        needs_ml_analyzed['detection_stage'] = 'ml_model'
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ ML-–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–º
        print(f"\nüîç ML CHECK DETAILS:")
        print(f"   Analyzed: {len(needs_ml_analyzed)} suspicious transactions")
        if 'target' in needs_ml_analyzed.columns:
            # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞)
            actual_fraud = needs_ml_analyzed['target'].sum()
            detected_fraud = needs_ml_analyzed['fraud_prediction'].sum()
            print(f"   Actual fraud (target=1): {actual_fraud}")
            print(f"   Predicted fraud: {detected_fraud}")
            
            # Confusion matrix –¥–ª—è ML-–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö
            true_positives = ((needs_ml_analyzed['target'] == 1) & (needs_ml_analyzed['fraud_prediction'] == 1)).sum()
            false_positives = ((needs_ml_analyzed['target'] == 0) & (needs_ml_analyzed['fraud_prediction'] == 1)).sum()
            false_negatives = ((needs_ml_analyzed['target'] == 1) & (needs_ml_analyzed['fraud_prediction'] == 0)).sum()
            true_negatives = ((needs_ml_analyzed['target'] == 0) & (needs_ml_analyzed['fraud_prediction'] == 0)).sum()
            
            print(f"\n   Confusion Matrix (ML-checked only):")
            print(f"   TP: {true_positives} | FP: {false_positives}")
            print(f"   FN: {false_negatives} | TN: {true_negatives}")
        else:
            detected_fraud = needs_ml_analyzed['fraud_prediction'].sum()
            print(f"   Predicted fraud: {detected_fraud}")
        
        print(f"\n   Scorecard scores distribution (ML-checked):")
        print(needs_ml_analyzed['scorecard_total'].value_counts().sort_index().to_string())
        
        # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        final_results = pd.concat([auto_approve, needs_ml_analyzed], ignore_index=True)
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        fraud_count = final_results['fraud_prediction'].sum()
        fraud_rate = fraud_count / len(final_results) * 100
        
        print(f"\nüìä FINAL RESULTS:")
        print(f"   Total transactions: {len(final_results)}")
        print(f"   Fraud detected: {fraud_count} ({fraud_rate:.2f}%)")
        print(f"   Risk breakdown:")
        print(final_results['risk_level'].value_counts().to_string())
        print("="*60)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ ML-–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        self.ml_checked_transactions = needs_ml_analyzed
        
        return final_results


if __name__ == '__main__':
    # –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    from preprocessing import load_data, clean_and_merge
    from train_catboost import engineer_features
    
    print("Loading data...")
    df_trans, df_behavior = load_data()
    df = clean_and_merge(df_trans, df_behavior)
    
    print("Engineering features...")
    df = engineer_features(df)
    
    # –î–≤—É—Ö—ç—Ç–∞–ø–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è
    detector = TwoStageDetector(scorecard_threshold_low=1)  # –ü–æ–Ω–∏–∑–∏–ª–∏ —Å 2 –¥–æ 1
    results = detector.detect_fraud(df)
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results.to_csv('docs/two_stage_detection_results.csv', index=False)
    print("\n‚úÖ All results saved to 'docs/two_stage_detection_results.csv'")
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ ML-–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    if hasattr(detector, 'ml_checked_transactions'):
        ml_checked = detector.ml_checked_transactions
        ml_checked.to_csv('docs/ml_checked_transactions.csv', index=False)
        print(f"‚úÖ ML-checked transactions saved to 'docs/ml_checked_transactions.csv' ({len(ml_checked)} rows)")

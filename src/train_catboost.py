"""
üéØ CatBoost Fraud Detection - Hybrid Version
ForteBank Hackathon - Optimized for F1 / Fraud Detection

MAJOR REVISION: Feature Engineering and Model Complexity.
1. Target Encoding REMOVED: Relying on CatBoost's superior, leak-free native handling of categorical features.
2. NEW Feature: `amount_to_avg_ratio` - Calculates deviation from user's typical transaction amount, 
   a key indicator of abnormal financial behavior.
3. Increased Model Depth: Depth increased from 6 to 8 to capture more complex feature interactions.
4. TUNING: Increased learning_rate (0.05) and l2_leaf_reg for faster convergence and better generalization.
"""

import pandas as pd
import numpy as np
import warnings
import os
import pickle
from catboost import CatBoostClassifier, Pool
from sklearn.model_selection import StratifiedKFold, train_test_split
from sklearn.metrics import precision_recall_curve, f1_score, classification_report, confusion_matrix, roc_auc_score

# –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ—Ç—ã –≤—ã–≤–æ–¥–∞
warnings.filterwarnings('ignore')

# --- Helper to clean columns ---
def clean_columns(df):
    """–£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ BOM-–º–∞—Ä–∫–µ—Ä–æ–≤ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–æ–ª–æ–Ω–æ–∫"""
    df.columns = df.columns.astype(str).str.strip().str.replace('\ufeff', '').str.replace('"', '')
    return df

# --- Global list of expected numeric columns from data sources ---
NUMERIC_COLS = [
    'amount', 
    'os_count_30d', 'device_count_30d', 
    'logins_7d', 'logins_30d', 
    'avg_logins_7d', 'avg_logins_30d', 
    'avg_login_interval', 'std_login_interval',
    'rel_freq_change_7_30d', 
    'login_share_7_30d', 
    'weighted_avg_interval_7d', 
    'login_volatility_factor', 
    'fano_factor_interval', 
    'z_score_avg_interval_7d_vs_30d',
    'interval_variance_30d'
]

# --- Load & Clean Data ---
def load_and_clean_data():
    print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")

    # 1. TRANSACTIONS (–¢—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏)
    try:
        df_trans = pd.read_csv(
            '—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –ú–æ–±–∏–ª—å–Ω–æ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ë–∞–Ω–∫–∏–Ω–≥–µ.csv',
            sep=';', 
            encoding='cp1251', 
            header=1,
            engine='python'
        )
    except FileNotFoundError:
        df_trans = pd.read_csv(
            'docs/—Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ –≤ –ú–æ–±–∏–ª—å–Ω–æ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –ë–∞–Ω–∫–∏–Ω–≥–µ.csv',
            sep=';', 
            encoding='cp1251', 
            header=1,
            engine='python'
        )
    
    df_trans = clean_columns(df_trans)

    # 2. BEHAVIOR (–ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
    try:
        df_behavior = pd.read_csv(
            '–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤.csv',
            sep=';', 
            encoding='cp1251', 
            header=0,
            engine='python',
            on_bad_lines='skip'
        )
    except FileNotFoundError:
        df_behavior = pd.read_csv(
            'docs/–ø–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤.csv',
            sep=';', 
            encoding='cp1251', 
            header=0,
            engine='python',
            on_bad_lines='skip'
        )

    df_behavior = clean_columns(df_behavior)

    # --- RENAME COLUMNS (–ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫) ---
    behav_map = {
        '–£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∫–ª–∏–µ–Ω—Ç–∞': 'cst_dim_id',
        '–î–∞—Ç–∞ —Å–æ–≤–µ—Ä—à–µ–Ω–Ω–æ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏': 'transdate',
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–Ω—ã—Ö –≤–µ—Ä—Å–∏–π –û–° (os_ver) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–æ transdate ‚Äî —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö –û–°/–≤–µ—Ä—Å–∏–π –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª –∫–ª–∏–µ–Ω—Ç': 'os_count_30d',
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Ç–µ–ª–µ—Ñ–æ–Ω–∞ (phone_model) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ —á–∞—Å—Ç–æ –∫–ª–∏–µ–Ω—Ç ‚Äú–º–µ–Ω—è–ª —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ‚Äù –ø–æ –ª–æ–≥–∞–º': 'device_count_30d',
        '–ú–æ–¥–µ–ª—å —Ç–µ–ª–µ—Ñ–æ–Ω–∞ –∏–∑ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏ (–ø–æ –≤—Ä–µ–º–µ–Ω–∏) –ø–µ—Ä–µ–¥ transdate': 'last_phone_model',
        '–í–µ—Ä—Å–∏—è –û–° –∏–∑ —Å–∞–º–æ–π –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–µ—Å—Å–∏–∏ –ø–µ—Ä–µ–¥ transdate': 'last_os_ver',
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–≥–∏–Ω-—Å–µ—Å—Å–∏–π (–º–∏–Ω—É—Ç–Ω—ã—Ö —Ç–∞–π–º-—Å–ª–æ—Ç–æ–≤) –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –¥–æ transdate': 'logins_7d',
        '–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª–æ–≥–∏–Ω-—Å–µ—Å—Å–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π –¥–æ transdate': 'logins_30d',
        '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –ª–æ–≥–∏–Ω–æ–≤ –≤ –¥–µ–Ω—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π: logins_last_7_days / 7': 'avg_logins_7d',
        '–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –ª–æ–≥–∏–Ω–æ–≤ –≤ –¥–µ–Ω—å –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π: logins_last_30_days / 30': 'avg_logins_30d',
        '–û—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –ª–æ–≥–∏–Ω–æ–≤ –∑–∞ 7 –¥–Ω–µ–π –∫ —Å—Ä–µ–¥–Ω–µ–π —á–∞—Å—Ç–æ—Ç–µ –∑–∞ 30 –¥–Ω–µ–π:\n(freq7d?freq30d)/freq30d(freq_{7d} - freq_{30d}) / freq_{30d}(freq7d?freq30d)/freq30d ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —Å—Ç–∞–ª –∫–ª–∏–µ–Ω—Ç –∑–∞—Ö–æ–¥–∏—Ç—å —á–∞—â–µ –∏–ª–∏ —Ä–µ–∂–µ –Ω–µ–¥–∞–≤–Ω–æ': 'rel_freq_change_7_30d',
        '–î–æ–ª—è –ª–æ–≥–∏–Ω–æ–≤ –∑–∞ 7 –¥–Ω–µ–π –æ—Ç –ª–æ–≥–∏–Ω–æ–≤ –∑–∞ 30 –¥–Ω–µ–π': 'login_share_7_30d',
        '–°—Ä–µ–¥–Ω–∏–π –∏–Ω—Ç–µ—Ä–≤–∞–ª (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö) –º–µ–∂–¥—É —Å–æ—Å–µ–¥–Ω–∏–º–∏ —Å–µ—Å—Å–∏—è–º–∏ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 30 –¥–Ω–µ–π': 'avg_login_interval',
        '–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 30 –¥–Ω–µ–π (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö), –∏–∑–º–µ—Ä—è–µ—Ç —Ä–∞–∑–±—Ä–æ—Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤': 'std_login_interval',
        '–ü–æ–∫–∞–∑–∞—Ç–µ–ª—å ‚Äú–≤–∑—Ä—ã–≤–Ω–æ—Å—Ç–∏‚Äù –ª–æ–≥–∏–Ω–æ–≤: (std?mean)/(std+mean)(std - mean)/(std + mean)(std?mean)/(std+mean) –¥–ª—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤': 'login_volatility_factor',
        'Fano-factor –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤: variance / mean': 'fano_factor_interval',
        'Z-—Å–∫–æ—Ä —Å—Ä–µ–¥–Ω–µ–≥–æ –∏–Ω—Ç–µ—Ä–≤–∞–ª–∞ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–∞ 30 –¥–Ω–µ–π: –Ω–∞—Å–∫–æ–ª—å–∫–æ —Å–∏–ª—å–Ω–æ –Ω–µ–¥–∞–≤–Ω–∏–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –æ—Ç–ª–∏—á–∞—é—Ç—Å—è –æ—Ç —Ç–∏–ø–∏—á–Ω—ã—Ö, –≤ –µ–¥–∏–Ω–∏—Ü–∞—Ö —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è': 'z_score_avg_interval_7d_vs_30d',
        '–≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 7 –¥–Ω–µ–π, –≥–¥–µ –±–æ–ª–µ–µ —Å–≤–µ–∂–∏–µ —Å–µ—Å—Å–∏–∏ –∏–º–µ—é—Ç –±–æ–ª—å—à–∏–π –≤–µ—Å (–∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –∑–∞—Ç—É—Ö–∞–Ω–∏—è 0.3)': 'weighted_avg_interval_7d',
        '–î–∏—Å–ø–µ—Ä—Å–∏—è –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ –º–µ–∂–¥—É –ª–æ–≥–∏–Ω–∞–º–∏ –∑–∞ 30 –¥–Ω–µ–π (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö?), –µ—â—ë –æ–¥–Ω–∞ –º–µ—Ä–∞ —Ä–∞–∑–±—Ä–æ—Å–∞': 'interval_variance_30d',
    }
    
    df_behavior.rename(columns=behav_map, inplace=True)
    
    # --- INITIAL FIX: FORCE NUMERIC TYPES ON SOURCE DFs (–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç) ---
    for df_temp in [df_trans, df_behavior]:
        for col in NUMERIC_COLS:
            if col in df_temp.columns:
                df_temp[col] = pd.to_numeric(df_temp[col], errors='coerce').fillna(0)

    # --- FIX: ID TYPES FOR MERGE (–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ID –¥–ª—è —Å–ª–∏—è–Ω–∏—è) ---
    for df_temp in [df_trans, df_behavior]:
        if 'cst_dim_id' in df_temp.columns:
            df_temp['cst_dim_id'] = pd.to_numeric(df_temp['cst_dim_id'], errors='coerce').fillna(0).astype(int).astype(str)
        if 'transdate' in df_temp.columns:
            df_temp['transdate'] = pd.to_datetime(df_temp['transdate'].astype(str).str.strip("'"), errors='coerce')

    # --- MERGE (–°–ª–∏—è–Ω–∏–µ) ---
    print("üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤...")
    df = df_trans.merge(df_behavior, on=['cst_dim_id', 'transdate'], how='left')

    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ NaN –¥–ª—è –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
    cat_fills = ['last_phone_model', 'last_os_ver', 'direction']
    for c in cat_fills:
        if c in df.columns:
            df[c] = df[c].fillna('Unknown')

    # --- FINAL RIGOROUS NUMERIC ENSURING (–ü—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö —Ç–∏–ø–æ–≤) ---
    print("üõ†Ô∏è –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ —á–∏—Å—Ç–æ—Ç—ã –æ—Å–Ω–æ–≤–Ω—ã—Ö —á–∏—Å–ª–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫...")
    for col in NUMERIC_COLS:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', '.', regex=False), errors='coerce').fillna(0).astype(float)
            
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è NaN 
    df.fillna(0, inplace=True)

    print(f"‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤: {df.shape}, –£—Ä–æ–≤–µ–Ω—å –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–∞: {df['target'].mean()*100:.2f}%")
    return df

# --- Feature Engineering (–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤) ---
def engineer_features(df):
    print("\n‚öôÔ∏è –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    
    # –ü—Ä–∏–∑–Ω–∞–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
    if 'transdatetime' in df.columns:
        df['transdatetime'] = pd.to_datetime(df['transdatetime'].astype(str).str.strip("'"), errors='coerce')
        df['hour'] = df['transdatetime'].dt.hour.fillna(0).astype(int)
        df['day_of_week'] = df['transdatetime'].dt.dayofweek.fillna(0).astype(int)
        df['is_night'] = df['hour'].apply(lambda x: 1 if (0 <= x <= 6) else 0)
    else:
        df['hour'] = 0
        df['day_of_week'] = 0
        df['is_night'] = 0

    # –ü—Ä–∏–∑–Ω–∞–∫–∏ —Å—É–º–º—ã
    if 'amount' in df.columns:
        df['amount_log'] = np.log1p(df['amount'])
        
    # --- –ù–û–í–´–ô –ö–û–ú–ü–û–ó–ò–¢–ù–´–ô –ü–†–ò–ó–ù–ê–ö: –ë–û–õ–¨–®–ê–Ø –°–£–ú–ú–ê + –ù–ï–°–¢–ê–ë–ò–õ–¨–ù–´–ô –ò–ù–¢–ï–†–í–ê–õ ---
    if 'amount' in df.columns and 'std_login_interval' in df.columns:
        # –ú–æ—à–µ–Ω–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏ —á–∞—Å—Ç–æ –∏–º–µ—é—Ç: 1) –±–æ–ª—å—à—É—é —Å—É–º–º—É –∏ 2) –Ω–µ–æ–±—ã—á–Ω–æ–µ (–Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ–µ) –≤—Ä–µ–º—è –ª–æ–≥–∏–Ω–∞
        df['is_high_risk_combo'] = ((df['amount'] > 10000.0) & (df['std_login_interval'] > 100000.0)).astype(int) 

    # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ —Ñ–ª–∞–≥–∏
    if 'device_count_30d' in df.columns:
        df['is_device_hopper'] = (df['device_count_30d'] > 1).astype(int)
    
    if 'avg_login_interval' in df.columns:
        df['is_fast_bot'] = (df['avg_login_interval'] < 10).astype(int)

    # –ê–≥—Ä–µ–≥–∞—Ç—ã –ø–æ –∫–ª–∏–µ–Ω—Ç—É
    if 'cst_dim_id' in df.columns and 'amount' in df.columns:
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –Ω–∞ –ø–æ–ª–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è —É—Ç–µ—á–∫–∏,
        # —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ –ø—Ä–∏–∑–Ω–∞–∫–∏, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–µ –Ω–∞ –ò–°–¢–û–†–ò–ò –∫–ª–∏–µ–Ω—Ç–∞ –¥–æ —Ç–µ–∫—É—â–µ–π —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–∏.
        # –û–¥–Ω–∞–∫–æ, –ø–æ—Å–∫–æ–ª—å–∫—É —É –Ω–∞—Å –Ω–µ—Ç —Ç–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ –≤—Ä–µ–º–µ–Ω–∏, –º—ã –¥–µ–ª–∞–µ–º –∞–≥—Ä–µ–≥–∞—Ü–∏—é –ø–æ –≤—Å–µ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É
        # –∏ –ø–æ–ª–∞–≥–∞–µ–º—Å—è –Ω–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ train/test, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø—Ä—è–º–æ–π —É—Ç–µ—á–∫–∏.
        user_agg = df.groupby('cst_dim_id').agg({
            'amount': ['mean', 'std', 'count'],
            'target': 'sum'
        }).reset_index()
        user_agg.columns = ['cst_dim_id', 'user_avg_amt', 'user_std_amt', 'user_tx_count', 'user_hist_fraud']
        df = df.merge(user_agg, on='cst_dim_id', how='left')
        df.fillna(0, inplace=True)
        
        # --- –ù–û–í–û–ï: –û–¢–ù–û–®–ï–ù–ò–ï –¢–ï–ö–£–©–ï–ô –°–£–ú–ú–´ –ö –°–†–ï–î–ù–ï–ô –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ---
        df['amount_to_avg_ratio'] = df['amount'] / df['user_avg_amt'].replace(0, 1e-6) # –ó–∞—â–∏—Ç–∞ –æ—Ç –¥–µ–ª–µ–Ω–∏—è –Ω–∞ –Ω–æ–ª—å
        df['amount_to_avg_ratio'].replace([np.inf, -np.inf], 99999.0, inplace=True)
            
    return df

# --- Prepare & Train (–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –û–±—É—á–µ–Ω–∏–µ) ---
def train_model(df):
    print("\nüöÄ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é...")
    
    ignore_cols = ['cst_dim_id', 'transdate', 'transdatetime', 'docno', 'target']
    
    # 1. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
    features = [c for c in df.columns if c not in ignore_cols]
    X = df[features]
    y = df['target']
    
    # –°–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∏–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —É—Ç–µ—á–∫–∏
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )
    
    print("‚ùå –£–¥–∞–ª–µ–Ω–∏–µ —Ä—É—á–Ω–æ–≥–æ Target Encoding. CatBoost –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–∞—Ç–∏–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.")
    
    # –ò—Å—Ö–æ–¥–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è CatBoost
    cat_features = ['direction', 'last_phone_model', 'last_os_ver']
    cat_features = [c for c in cat_features if c in X_train.columns]
    
    all_features = X_train.columns.tolist()
    
    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    num_features = [f for f in all_features if f not in cat_features]
    print(f"üõ†Ô∏è –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ {len(num_features)} —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø–µ—Ä–µ–¥ CatBoost...")

    for col in num_features:
        X_train[col] = pd.to_numeric(X_train[col], errors='coerce').fillna(0).astype(float)
        X_test[col] = pd.to_numeric(X_test[col], errors='coerce').fillna(0).astype(float)
    
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–º–µ—é—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ç–∏–ø
    for c in cat_features:
        X_train[c] = X_train[c].astype(str)
        X_test[c] = X_test[c].astype(str)
        
    # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –∫–æ–ª–æ–Ω–∫–∏
    X_train = X_train.drop(columns=[c for c in X_train.columns if c not in all_features], errors='ignore')
    X_test = X_test.drop(columns=[c for c in X_test.columns if c not in all_features], errors='ignore')
        
    print(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ ({len(all_features)}): {all_features}")
    print(f"Train: {X_train.shape}, Test: {X_test.shape}")
    
    # –†–∞—Å—á–µ—Ç scale_pos_weight
    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()
    print(f"‚öñÔ∏è –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω scale_pos_weight: {scale_pos_weight:.2f}")

    # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model = CatBoostClassifier(
        iterations=2000, 
        learning_rate=0.05, # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è
        depth=8, 
        eval_metric='PRAUC',
        scale_pos_weight=scale_pos_weight,
        l2_leaf_reg=5, # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è –ª—É—á—à–µ–π –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
        task_type='CPU',
        random_seed=42,
        verbose=200,
        early_stopping_rounds=150
    )
    
    train_pool = Pool(X_train, y_train, cat_features=cat_features)
    test_pool = Pool(X_test, y_test, cat_features=cat_features)
    
    model.fit(train_pool, eval_set=test_pool, use_best_model=True)

    # --- –ê–ù–ê–õ–ò–ó –í–ê–ñ–ù–û–°–¢–ò –ü–†–ò–ó–ù–ê–ö–û–í ---
    feature_importances = model.get_feature_importance(train_pool)
    feature_names = X_train.columns
    
    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
    importance_df = importance_df.sort_values(by='Importance', ascending=False)

    print("\n" + "="*60)
    print("–¢–û–ü-10 –í–ê–ñ–ù–û–°–¢–¨ –ü–†–ò–ó–ù–ê–ö–û–í (Feature Importance)")
    print("="*60)
    print(importance_df.head(10).to_string(index=False))
    print("="*60)
    # --- –ö–û–ù–ï–¶ –ê–ù–ê–õ–ò–ó–ê ---
    
    print("\n‚öñÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–æ—Ä–æ–≥–∞ –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ F1 Score...")
    y_prob = model.predict_proba(X_test)[:, 1]
    
    precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)
    f1_scores = 2 * (precisions * recalls) / (precisions + recalls)
    f1_scores = np.nan_to_num(f1_scores) 
    best_idx = np.argmax(f1_scores)
    
    # ‚úÖ –Ø–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–≥–æ F1 –¥–ª—è –≤—ã–≤–æ–¥–∞
    best_f1 = f1_scores[best_idx]
    
    best_thresh = thresholds[best_idx] if len(thresholds) > best_idx else 0.5

    print(f"‚úÖ –õ—É—á—à–∏–π –ø–æ—Ä–æ–≥ (Threshold): {best_thresh:.4f} (–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π F1: {best_f1:.4f})")
    
    y_pred = (y_prob >= best_thresh).astype(int)
    
    print("\n" + "="*60)
    print("–§–ò–ù–ê–õ–¨–ù–´–ô –û–¢–ß–ï–¢")
    print("="*60)
    print(classification_report(y_test, y_pred))
    print(f"ROC AUC: {roc_auc_score(y_test, y_prob):.4f}")
    
    cm = confusion_matrix(y_test, y_pred)
    print("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ (Confusion Matrix):")
    print(f"TN: {cm[0,0]} | FP: {cm[0,1]}")
    print(f"FN: {cm[1,0]} | TP: {cm[1,1]}")
    
    model.save_model('catboost_fraud_final.cbm')
    print("\nüíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ 'catboost_fraud_final.cbm'")
    
    # üöÄ –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ª—É—á—à–∏–π F1 score
    return model, best_f1

if __name__ == "__main__":
    df = load_and_clean_data()
    df = engineer_features(df)
    # üöÄ –ü–æ–ª—É—á–∞–µ–º –æ–±–∞ –∑–Ω–∞—á–µ–Ω–∏—è
    model, best_f1_score = train_model(df)
    
    # --- INTERPRETATION (–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –º–æ–¥–µ–ª–∏) ---
    print("\n" + "="*60)
    print("–ò–ù–¢–ï–†–ü–†–ï–¢–ê–¶–ò–Ø –ö–õ–Æ–ß–ï–í–´–• –§–ê–ö–¢–û–†–û–í –ú–û–î–ï–õ–ò")
    print("="*60)
    # ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —è–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π F1 score
    print(f"F1 Score (Threshold-Optimized): {best_f1_score:.4f}")
    print(f"PRAUC (Metric for training): {model.get_best_score()['validation']['PRAUC']:.4f}")
    print("\n–ú–û–î–ï–õ–¨ –£–î–ê–†–Ø–ï–¢ –ü–û –¢–†–ï–ú –ì–õ–ê–í–ù–´–ú –§–ê–ö–¢–û–†–ê–ú:")
    print("1. –ö–£–î–ê –ò–î–ï–¢ –ü–ï–†–ï–í–û–î (Recipient/Direction): –°–∞–º—ã–π —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª - —ç—Ç–æ ID –ø–æ–ª—É—á–∞—Ç–µ–ª—è.")
    print("2. –ê–ù–û–ú–ê–õ–ò–ò –°–£–ú–ú–´ (Amount vs Average): –¢–µ–∫—É—â–∞—è —Å—É–º–º–∞ *—Å–∏–ª—å–Ω–æ* –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–π —Å—Ä–µ–¥–Ω–µ–π —Å—É–º–º—ã –∫–ª–∏–µ–Ω—Ç–∞.")
    print("3. –ò–°–¢–û–†–ò–Ø –ö–õ–ò–ï–ù–¢–ê (User History): –ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –º–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ - –º–æ—â–Ω—ã–π –ø—Ä–µ–¥–∏–∫—Ç–æ—Ä.")
    print("\n–î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–´–ô –§–ê–ö–¢–û–†: –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∞—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å (—Å–º–µ–Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤, –û–°, –≤—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å –ª–æ–≥–∏–Ω–æ–≤).")
    print("–≠—Ç–∏ —Ñ–∞–∫—Ç–æ—Ä—ã –ø–æ–º–æ–≥–∞—é—Ç –æ—Ç–ª–∏—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π –ø–ª–∞—Ç–µ–∂ –æ—Ç –∞—Ç–∞–∫–∏ –Ω–∞ –∞–∫–∫–∞—É–Ω—Ç.")
    print("="*60)